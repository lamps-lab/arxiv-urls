<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Weighted asymmetric least squares regression with fixed-effects</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-08-11">August 11, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Amadou</forename><surname>Barry</surname></persName>
							<email>amadou.barry@mail.mcgill.ca.</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Departments of Epidemiology</orgName>
								<orgName type="department" key="dep2">Biostatistics and Occupational Health</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Lady Davis Institute</orgName>
								<orgName type="institution" key="instit2">Jewish General Hospital</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Karim</forename><surname>Oualkacha</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics and Statistics</orgName>
								<orgName type="institution">Université du Québec à Montréal</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Arthur</forename><surname>Charpentier</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics and Statistics</orgName>
								<orgName type="institution">Université du Québec à Montréal</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Weighted asymmetric least squares regression with fixed-effects</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-08-11">August 11, 2021</date>
						</imprint>
					</monogr>
					<idno type="MD5">4153A8808A81B9AE4CEEC1BAE2998F5E</idno>
					<idno type="arXiv">arXiv:2108.04737v1[econ.EM]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-01-29T07:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Expectile regression</term>
					<term>quantile regression</term>
					<term>fixed-effects</term>
					<term>within-transformation</term>
					<term>endogenous model</term>
					<term>panel data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The fixed-effects model estimates the regressor effects on the mean of the response, which is inadequate to summarize the variable relationships in the presence of heteroscedasticity. In this paper, we adapt the asymmetric least squares (expectile) regression to the fixed-effects model and propose a new model: expectile regression with fixed-effects (ERFE). The ERFE model applies the within transformation strategy to concentrate out the incidental parameter and estimates the regressor effects on the expectiles of the response distribution. The ERFE model captures the data heteroscedasticity and eliminates any bias resulting from the correlation between the regressors and the omitted factors. We derive the asymptotic properties of the ERFE estimators and suggest robust estimators of its covariance matrix. Our simulations show that the ERFE estimator is unbiased and outperforms its competitors. Our real data analysis shows its ability to capture data heteroscedasticity (see our R package, github.com/AmBarry/erfe).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The fixed-effects (FE) model is commonly used in econometric to analyze panel data. The FE model has the ability to account for the correlation between the regressors and the omitted (unmeasured) factors which is common in many applications. For example, in econometrics, the education level is known to be correlated with the individual unobserved ability <ref type="bibr" target="#b8">(Card, 2001)</ref>.</p><p>In perinatal studies, the birth weight is influenced by maternal genetic <ref type="bibr" target="#b24">(Warrington et al., 2019)</ref>, which is usually a missing information. Therefore, in such context-where the unmeasured factors are correlated with the regressors, the FE estimator (within-estimator) is unbiased, consistent and computationally efficient <ref type="bibr" target="#b10">(Cornwell and Rupert, 1988)</ref>.</p><p>Several quantile regression (QR)-based methods <ref type="bibr" target="#b15">(Koenker, 2004;</ref><ref type="bibr" target="#b11">Galvao and Montes-Rojas, 2010;</ref><ref type="bibr" target="#b18">Lamarche, 2010)</ref> have been proposed to overcome the heteroscedasticity problem in the FE framework. However, they fail to extend the favorable properties of the within-estimator and suffer from two significant limitations. First, the fixed-effects QR-based methods do not extend the within-transformation strategy to solve the incidental parameter problem. Thus, the fixed-effects QR-based methods simultaneously estimate the parameter of interest and the incidental parameter which results in a computationally demanding algorithm. Additionally, the covariance of the QR-based methods is based on the random error density function which further adds a computational burden and certain numerical issues <ref type="bibr" target="#b9">(Chen et al., 2004;</ref><ref type="bibr" target="#b26">Yin and Cai, 2005;</ref><ref type="bibr" target="#b14">Kocherginsky et al., 2005)</ref>. Second, the fixed-effects QR-based method do not control for the correlation between the individual effects and the regressors. Thus, in the presence of such correlations, the fixed-effects QR-based method yields biased and inconsistent estimates.</p><p>In this paper, we rely on expectiles to successfully generalize the within-estimator and take into account the heteroscedasticity present in the panel data under the FE framework. To the best of our knowledge, this is the first approach that estimates the marginal effect of the regressors on the response distribution, and generalizes the within transformation strategy in the FE framework.</p><p>The expectiles are statistics that characterize the distribution function of a random variable <ref type="bibr" target="#b12">(Girard et al., 2021)</ref>. The expectiles and the expectile regression (ER) were introduced in the seminal paper by <ref type="bibr" target="#b21">Newey and Powell (1987)</ref>. The expectiles and quantiles play similar statistical roles, except that expectiles are weighted averages while quantiles are order statistics. This interpretation difference offers significant computational advantages. In other words, quantiles focus on the ordering of the observations while the expectiles target their values. For instance, the mean is a particular expectile as the median is a particular quantile. The research on expectiles is very active and for further details we refer to <ref type="bibr" target="#b3">Barry et al. (2020)</ref>.</p><p>Typically quantiles are more robust than expectiles, but as mentioned earlier, the proposed QRbased fixed-effects models can not extend the within transformation strategy to solve the computational challenges raised by the incidental parameter problem efficiently. Further, the QR-based fixed-effects models fail to control for the correlation between the individual effects and the regressors. Therefore, the expectile-based approach could be an effective alternative for inference in the FE framework.</p><p>In this paper, we combine the weighted asymmetric least squares regression (ER) and the FE model to propose a new panel model that we call: expectile regression for fixed-effects model (ERFE). The ERFE model retains the attractive properties of the FE model, while accounting for the heteroskedasticity present in the panel data. We derive its asymptotic properties and propose a heterogeneous, consistent, and robust estimator of its variance-covariance matrix. We share our code as a free R package available on GitHub (github.com/AmBarry/erfe) to simplify its implementation.</p><p>Our main contributions are: i. Extension of the within-transformation strategy in the ER framework to solve the incidental parameter problem, offering a significant computational advantage particularly with the advent of high dimensional data, where the sample size can be very large; ii.</p><p>Elimination of any bias that might result from the correlation between the individual effects and the regressors; iii. Derivation of the asymptotic properties of the ERFE estimators; iv. Proposition of an estimator of its variance-covariance matrix for inference.</p><p>Our ERFE model accounts for the omitted time-invariant factors and their correlation with the regressors present in the model. It also captures the heteroskedasticity present in the panel data by estimating the effects of the regressors at the conditional expectiles of the response distribution. Indeed, in the presence of heteroskedasticity, the parameters of the model are function of the asymmetric points, and in this case the ERFE model captures the heteroskedasticity by estimating several regression coefficient vectors at different locations of the conditional response distribution. The ERFE model provides a detailed overview of the regressor effects on the response distribution without making any assumption about the random error distribution. Our ERFE model is computationally efficient and easy to implement, with its available R package.</p><p>We believe that it will be a useful tool for addressing the heteroskedasticity present in the panel data.</p><p>In Section 2, we introduce the expectile function and the expectile regression model, and then present the expectile regression with fixed-effects (ERFE) model. In Section 3, we derive the asymptotic properties of the ERFE estimator, and propose an estimator of its variance-covariance (VC) matrix. We present the sample performance of the ERFE estimator in Section 4 and its application to a real dataset in Section 5. The conclusions is in Section 6 and detail of the proofs are in the Supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Models and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Expectile and expectile regression</head><p>The expectile of level τ ∈ [0, 1] of a random variable Y is defined as the unique solution of</p><formula xml:id="formula_0">µ τ (Y) = argmin θ ∈ R E{ρ τ (Y -θ)},<label>(1)</label></formula><p>where ρ τ (t) = |τ -1(t ≤ 0)| • t 2 is the asymmetric square loss function that assigns weights τ and 1τ to positive and negative deviations, respectively.</p><p>The expectiles summarize the cumulative distribution function of a random variable. In this regard, the expectiles play a similar statistical role to the quantiles, except that quantiles are order statistics while expectiles are weighted averages, and this interpretation difference is accompanied by significant computational advantages. The expectiles generalize the mean which corresponds to the expectile of level τ = 0.5 and assigns the same weight to positive and negative deviations. The expectiles are location and scale equivariant, that is for s &gt; 0 and t ∈ R, µ τ (sY + t) = sµ τ (Y) + t. A detailed study of the expectiles can be found in <ref type="bibr" target="#b21">(Newey and Powell, 1987)</ref>.</p><p>Once the optimization problem of equation ( <ref type="formula" target="#formula_0">1</ref>) is solved, for a fixed τ, the expectile of the random variable Y can be defined as a weighted average:</p><formula xml:id="formula_1">µ τ (Y) = µ τ = E ψ τ (Y -µ τ ) E ψ τ (Y -µ τ ) Y ,</formula><p>where ψ τ (t) = |τ -1(t ≤ 0)| is the check function. The only subtlety is that the weights are random. Given a random sample, {(y i )} n i=1 , the corresponding τ-th sample expectile</p><formula xml:id="formula_2">µ τ = n ∑ i=1 ψ τ (y i -µ τ ) ∑ n l=1 ψ τ (y l -µ τ ) y i (2)</formula><p>is the weighted mean, where the weights depend on the sample data. For a fixed θ, equation ( <ref type="formula" target="#formula_75">2</ref>) is derived as the solution which minimizes the following empirical risk function:</p><formula xml:id="formula_3">1 n n ∑ i=1 ρ τ (y i -θ).</formula><p>(3)</p><p>In addition to the expectiles, <ref type="bibr" target="#b21">Newey and Powell (1987)</ref> introduced the expectile linear regression (ER) as a tool to study the regressor effects on the response distribution and capture the heteroscedasticity present in the data. Consider the following linear regression model</p><formula xml:id="formula_4">y i = x i T β + ε i with µ τ (ε i ) = 0,<label>(4)</label></formula><p>where x i is a p × 1 vector of regressors, y i and ε i are respectively the response variable and the random error with unspecified distribution function. The parameter of interest β ∈ R p is unknown and needs to be estimated. The assumption, µ τ (ε i ) = 0, ensures that the random error is centered on the τ-th expectile. The corresponding ER model, for a fixed τ ∈ (0, 1), is given as:</p><formula xml:id="formula_5">µ τ (y i |x i ) = x i T β τ .<label>(5)</label></formula><p>Therefore, the ER estimator β τ , for a fixed τ ∈ (0, 1), can be derived by minimizing the following objective function:</p><formula xml:id="formula_6">n ∑ i=1 ρ τ y i -x i T β τ over β τ ∈ R p .</formula><p>Since the loss function ρ τ (t) is continuously differentiable, we have through the first order condition:</p><formula xml:id="formula_7">β τ = n ∑ i=1 ψ τ (y i -x i T β τ )x i x i T -1 n ∑ i=1 ψ τ (y i -x i T β τ )x i y i ,<label>(6)</label></formula><p>where ψ τ (t) = |τ -1(t ≤ 0)| is the check function. The ER estimator can be computed as an iterated weighted least squares estimators. For the special case of τ = 0.5, β 0.5 is the classical ordinary least squares (OLS) estimator and this makes the ER a natural complement of the OLS regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fixed-effects model for panel data</head><p>Consider the standard linear fixed-effects model for panel data</p><formula xml:id="formula_8">y ij = x ij T β + α i + ε ij ,<label>(7)</label></formula><p>where y ij is the scalar response variable, the vector</p><formula xml:id="formula_9">x ij = (x 1 ij , x 2 ij , . . . , x p ij ) T ∈ R p</formula><p>is the vector of regressors measured on subject i at time j, the parameter α i is the subject-specific effects parameter, and the variable ε ij is a random error with unspecified distribution function. The equation model ( <ref type="formula" target="#formula_8">7</ref>) is conveniently represented in individual notation as:</p><formula xml:id="formula_10">y i = X i β + Z i α + ε i ,<label>(8)</label></formula><p>where y i and ε i are m × 1 vectors, X i is an m × p design matrix and Z i is an m × n incidence matrix and α is an n × 1 subject-specific effects vector. We can also stack all the data and represent the equation model ( <ref type="formula" target="#formula_10">8</ref>) as:</p><formula xml:id="formula_11">y = X β + Zα + ε, (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>where y and ε are N × 1 vectors, X and Z are respectively N × p and N × n matrices with N = mn. The incidence matrix Z identifies the n distinct subjects of the sample.</p><p>The fixed-effects Zα of model equation ( <ref type="formula" target="#formula_11">9</ref>) is infinite in nature and is potentially correlated with the regressors of the model. The traditional estimation method used to overcome this issue is the within-transformation strategy. This technique consists of pre-multiplying both sides of equation model ( <ref type="formula" target="#formula_11">9</ref>) by the idempotent matrix M Z = I N -Z(Z T Z) -1 Z T to eliminate the infinitedimensional parameter, and then applies the ordinary least squares (OLS) regression to the transformed data. The model that results from this transformation is represented as:</p><formula xml:id="formula_13">y * = X * β + ε * , (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>where y * = M Z y and X * and ε * are defined similarly. The OLS estimator of the fixed-effects model, known as the within-transformation estimator, is given as:</p><formula xml:id="formula_15">β = (X * T X * ) -1 X * T y * . (<label>11</label></formula><formula xml:id="formula_16">)</formula><p>The within-transformation estimator is consistent and asymptotically normally distributed <ref type="bibr" target="#b13">(Greene, 2011)</ref>. The within-transformation estimator is computationally efficient and is not affected by any bias resulting from the correlation between the individual effects and the regressors. The withintransformation technique does not allow estimation of the time-invariant regressors which could be seen as a limitation. However, this can be a strength when the number of time-invariant confounders is large, and when the collection of some of these variables (genetic factor) is complex and costly <ref type="bibr" target="#b5">(Brüderl and Ludwig, 2014)</ref>. In the following subsection, we present the expectile regression for fixed-effects (ERFE) model and derive the iterative-within-transformation ERFE estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">ERFE model for panel data</head><p>The ERFE model of the linear fixed-effects model is defined, for fixed τ ∈ (0, 1), as:</p><formula xml:id="formula_17">µ τ (y ij |α i , x ij ) = x ij T β τ + z ij T α. (<label>12</label></formula><formula xml:id="formula_18">)</formula><p>In this setting the parameter β τ ∈ R p captures the influence of the regressors x ij on the location, scale, and shape of the conditional distribution of the response variable y ij . The subject-specific effects α is assumed to be independent of τ across the percentiles and to have a pure locationshift effect on the conditional expectile of the response. Assuming a τ-dependency of the subject-specific effects implies estimating its distribution with m number of within-subject observations, which is relatively small in most applications. Take note that no assumption is made about the shape of the response distribution.</p><p>The corresponding ERFE estimator of model equation ( <ref type="formula" target="#formula_17">12</ref>) is defined as the vector minimizing the following objective function:</p><formula xml:id="formula_19">n ∑ i=1 m ∑ j=1 ρ τ y ij -x ij T β τ -z ij T α . (<label>13</label></formula><formula xml:id="formula_20">)</formula><p>Since the loss function ρ τ (•) is continuously differentiable, we can apply the first-order condition and derive the resulting ERFE estimator β τ , which is defined as:</p><formula xml:id="formula_21">β τ = X T Ψ τ y -X β τ -Z α M Z (τ)X -1 X T Ψ τ y -X β τ -Z α M Z (τ)y,<label>(14)</label></formula><p>where the diagonal check function matrix is:</p><formula xml:id="formula_22">Ψ τ y -X β τ -Z α = diag ψ τ (y 11 -x 11 T β τ -z 11 T α), . . . , ψ τ (y nm -x nm T β τ -z nm T α) . (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>The projection matrix M Z (τ) and its complement P Z (τ) are idempotent matrices and are defined as:</p><formula xml:id="formula_24">M Z (τ) = I N -P Z (τ), P Z (τ) = Z(Z T Ψ τ Z) -1 Z T Ψ τ .</formula><p>The function Ψ τ (•) defined in equation ( <ref type="formula" target="#formula_22">15</ref>) depends on the subject-specific parameter estimator α which, by the first-order condition of equation ( <ref type="formula" target="#formula_19">13</ref>), verifies the relationship:</p><formula xml:id="formula_25">Z α = P Z (τ)(y -X β τ ).<label>(16)</label></formula><p>Now, using equation ( <ref type="formula" target="#formula_25">16</ref>), the argument of the check function matrix can be written as</p><formula xml:id="formula_26">y -X β τ -Z α = M Z (τ)(y -X β τ ).<label>(17)</label></formula><p>Therefore, the incidental parameter estimate is eliminated from the expression of equation ( <ref type="formula" target="#formula_21">14</ref>)</p><p>of the ERFE estimator. Now, using the following relationship:</p><formula xml:id="formula_27">Ψ τ M Z (τ)(y -X β τ ) M Z (τ) = M Z T (τ)Ψ τ M Z (τ)(y -X β τ ) ,</formula><p>and the idempotent property of the projection matrix M Z (τ), we can rewrite the ERFE estimator as:</p><formula xml:id="formula_28">β τ = X T M Z (τ) T Ψ τ M Z (τ)(y -X β τ ) M Z (τ)X -1 × X T M Z (τ) T Ψ τ M Z (τ)(y -X β τ ) M Z (τ)y.<label>(18)</label></formula><p>In summary, the within-estimator is extended to the ER framework. The strategy is derived by applying the projection matrix M Z (τ) to the initial data [y, X], to eliminate the subject-specific effects parameter. Additionally, like the ER estimator in equation ( <ref type="formula" target="#formula_7">6</ref>), the within ERFE estimator can be computed iteratively using the iterative weighted least squares algorithm. The detailed algorithm for computing the iterative-within-transformation ERFE estimator is summarized in the following stepwise procedures.</p><p>Algorithm 1: The iterative within-transformation ERFE algorithm Input: Let, for a fixed τ, β (0) τ = β τ , the ER estimator and ε</p><formula xml:id="formula_29">(0) ijτ = y (0) ij -x (0) ij T β (0) τ . while β (r) τ -β (r-1) τ ∞ ≤ ζ do Given β (r-1) τ</formula><p>at the (r -1)-th step, update:</p><formula xml:id="formula_30">1. P (r) Z (τ) ← Z(Z T Ψ τ ( ε τ * (r-1) )Z) -1 Z T Ψ τ ( ε τ * (r-1) ), ε τ * (r-1) = y * (r-1) -X * (r-1) β (r-1) τ 2. y * (r) ← M (r) Z (τ)y 3. X * (r) ← M (r) Z (τ)X 4. β (r) τ ← β (r-1) τ end Return β τ</formula><p>The parameter ζ is the convergence tolerance and the default value in our code implementation is set to 10 -7 . In practice, Algorithm 1 is computationally efficient and usually the number of iterations required to achieve convergence is between 3 and 5. Note that when τ = 0.5 we have Ψ τ = 0.5I N and the iterative within-transformation ERFE estimator is nothing else than the OLS within-transformation estimator.</p><p>From the above development, the multiplication of a vector (say y) by the matrix M Z (τ) deviates that vector from its expectile as shown by the following expression:</p><formula xml:id="formula_31">M Z (τ)y = y 11 - m ∑ j=1 ψ τ ( ε 1j ) ∑ m k=1 ψ τ ( ε 1k ) y 1j , . . . , y 1m - m ∑ j=1 ψ τ ( ε 1j ) ∑ m k=1 ψ τ ( ε 1k ) y 1j , . . . , y n1 - m ∑ j=1 ψ τ ( ε nj ) ∑ m k=1 ψ τ ( ε nk ) y nj , . . . , y nm - m ∑ j=1 ψ τ ( ε nj ) ∑ m k=1 ψ τ ( ε nk ) y nj T .</formula><p>We can see, from this expression, how the projection matrix M Z (τ) eliminates the subject-specific effects parameter and any other time-invariant regressors from the initial model. For a matrix, like the design matrix X, the transformation is applied column-wise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ERFE model for a sequence of expectiles</head><p>The preceding development shows that the classical within-transformation strategy can be generalized in the ERFE framework. Now, we present the ERFE estimator for a sequence of expectiles using the transformed data. The sequence of expectiles, for example the mean and a few expectiles above and below it, is necessary in the description of the conditional distribution of the response variable and for capturing the data heteroscedasticity. In addition, the simultaneous estimation allows the multiple expectiles to share strength among each other and to gain better estimation accuracy than individually estimated expectile functions <ref type="bibr" target="#b19">(Liu and Wu, 2011)</ref>.</p><p>The iterative within-transformation ERFE estimator β τ = [ β τ 1 T , . . . , β τ q T ] T for a sequence of asymmetric points τ = (τ 1 , . . . , τ q ) T is defined as the minimum of the following objective function:</p><formula xml:id="formula_32">q ∑ k=1 n ∑ i=1 m ∑ j=1 v k ρ τ k y ij -x ij T β τ k -z ij T α . (<label>19</label></formula><formula xml:id="formula_33">)</formula><p>The vector v = (v 1 , . . . , v q ) T is the vector of weights controlling the relative influence of the q asymmetric points {τ 1 , . . . , τ q } and it choice depends on the research question. For a sequence of expectiles, the iterative within-transformation ERFE estimator is defined as:</p><formula xml:id="formula_34">β τ = (I q ⊗ X * ) T Ψ τ ( ε * τ )(V ⊗ X * ) -1 (V ⊗ X * ) T Ψ τ ( ε * τ )(1 q ⊗ y * )<label>(20)</label></formula><p>where</p><formula xml:id="formula_35">Ψ τ ( ε * τ ) = diag Ψ τ k ( y * -X * β τ k ) q k=1 , V = [diag(v k )]</formula><p>q k=1 and the transformed data</p><p>[(1 q ⊗ y * ), (I q ⊗ X * )] is obtained by pre-multiplying the matrix M Z (τ) to the initial data [y, X].</p><p>The projection matrix is defined as M Z (τ) = I nmq -P Z (τ) and</p><formula xml:id="formula_36">P Z (τ) = (v ⊗ Z) (v ⊗ Z) T Ψ τ ( ε * τ )(1 q ⊗ Z) -1 (1 q ⊗ Z) T Ψ τ ( ε * τ ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Asymptotic</head><p>In this section, the asymptotic properties of the ERFE estimator are presented. As stated by <ref type="bibr" target="#b15">Koenker (2004)</ref>, the presence of the incidence parameter, which has an infinite dimension, can raise some challenges. For this reason, we present first the asymptotic results of the ERFE estimator in the simplest case, namely for a single τ. We then present the asymptotic properties of the ERFE estimator for a simultaneous sequence of asymmetric points τ = (τ 1 , . . . , τ q ). The section ends with the suggestion of an estimator of the covariance matrix for the ERFE estimator.</p><p>All the proofs are available in the Supplementary file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Asymptotics for the ERFE estimator</head><p>Asymptotics for a single expectile</p><p>In the following, the asymmetric square-loss function of the ERFE model,</p><formula xml:id="formula_37">ρ τ y ij -x ij T β τ -z ij T α ,</formula><p>is replaced in term of optimization by the equivalent loss function</p><formula xml:id="formula_38">ρ τ y ij -µ ijτ -x ij T δ 1τ / √ nm -z ij T δ 0 / √ m -ρ τ (y ij -µ ijτ ),</formula><p>where µ ijτ = x ij T β τ + z ij T α. Now, observe that the following estimator</p><formula xml:id="formula_39">δ =    δ 0 δ 1τ    =    √ m( α -α) √ nm β τ -β τ   </formula><p>minimizes the new objective function</p><formula xml:id="formula_40">R nm (δ) = n ∑ i=1 m ∑ j=1 ρ τ y ij -µ ijτ -x ij T δ 1τ / √ nm -z ij T δ 0 / √ m -ρ τ (y ij -µ ijτ ).<label>(21)</label></formula><p>The asymptotic theory of the ERFE estimator is derived using this new objective function <ref type="bibr">(21)</ref> and under the following assumptions.</p><p>A1. The data {(y i , X i )} n i=1 are independent across i, and,</p><formula xml:id="formula_41">Var Ψ τ (ε iτ )ε iτ = E Ψ τ (ε iτ )ε iτ ε iτ T Ψ τ (ε iτ ) = Σ iτ ,</formula><p>where</p><formula xml:id="formula_42">ε iτ = (ε i1τ , . . . , ε imτ ) T , ε ijτ = y ij -x ij T β τ and Ψ τ (ε iτ ) = diag(ψ τ (ε ijτ )) m j=1</formula><p>.</p><p>A2. The limiting forms of the following matrices are positive definite</p><formula xml:id="formula_43">D 0 (τ) = lim m→∞ n→∞ m -1    Z T Σ τ Z Z T Σ τ X/ √ n X T Σ τ Z/ √ n X T Σ τ X/n    , D 1 (τ) = lim m→∞ n→∞ m -1    Z T E[Ψ τ (ε τ )]Z Z T E[Ψ τ (ε τ )]X/ √ n X T E[Ψ τ (ε τ )]Z/ √ n X T E[Ψ τ (ε τ )]X/n    ,</formula><p>where</p><formula xml:id="formula_44">Σ τ = Var[Ψ τ (ε τ )ε τ ] = diag[Σ iτ ] n i=1 .</formula><p>A3. The norm of the regressors is bounded by a positive constant M, max i,j x ij &lt; M.</p><p>The stated assumptions A1-A3 are standard for panel data models <ref type="bibr" target="#b15">(Koenker, 2004)</ref>. Condition A1 ensures independence across individuals, but allows a within-subject dependency and heterogeneity across individuals. Condition A2 is a full rank condition and is used to invoke the Lindeberg-Feller Central Limit Theorem. We observe that, when τ = 1/2 then D 1 (τ) simplifies and Condition A2 reduces to a condition on the matrices X T X/nm and Z T Z/m. Condition A3 is useful both for the application of the Lindeberg-Feller Central Limit Theorem and for ensuring the finite dimensional convergence of the objective function.</p><p>Theorem 1. Assume conditions A1-A3 are met, with n, m → ∞, and</p><formula xml:id="formula_45">E|ψ τ (ε ijτ )| 4+ν &lt; ∆ &lt; ∞ and E|ε ijτ | 4+ν &lt; ∆ &lt; ∞ for some ν &gt; 0.</formula><p>Then δ 1τ the components of the minimizer, δ, converge in distribution to a Gaussian random vector with mean zero and variance-covariance matrix given by the lower right p × p block of the matrix D -1 1 (τ)D 0 (τ)D -1 1 (τ). In others words</p><formula xml:id="formula_46">√ nm β τ -β τ d -→ N 0, D -1 1 (τ)D 0 (τ)D -1 1 (τ) 22 .</formula><p>To show the closed form of the above matrix</p><formula xml:id="formula_47">D -1 1 (τ)D 0 (τ)D -1 1 (τ)</formula><p>22 assume that the limiting forms of the following matrices are positive definite</p><formula xml:id="formula_48">D 0 (τ) = lim m→∞ n→∞ X T M Z (τ) T Σ τ M Z (τ)X, D 1 (τ) = lim m→∞ n→∞ X T M Z T (τ) E[Ψ τ (ε)]M Z (τ)X</formula><p>where M Z (τ) = I -P Z (τ) and</p><formula xml:id="formula_49">P Z (τ) = Z Z T E[Ψ τ (ε)]Z -1 Z T E[Ψ τ (ε)].</formula><p>Under the above conditions and the conditions of Theorem 1 it follows that:</p><p>Lemma 1.</p><formula xml:id="formula_50">D -1 1 (τ)D 0 (τ)D -1 1 (τ) 22 = D -1 1 (τ) D 0 (τ) D -1 1 (τ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asymptotics for several expectiles</head><p>The asymptotic properties of the ERFE estimator for a sequence of asymmetric points τ = (τ 1 , • • • , τ q ) are derived using the transformed data, [y * ; X * ], where X * = M Z (τ)X and y * = M Z (τ)y. Both projection matrices M Z (τ) and P Z (τ) are idempotent and are defined as:</p><formula xml:id="formula_51">M Z (τ) = I N -P Z (τ), P Z (τ) = Z(Z T E[Ψ τ (ε * τ )]Z) -1 Z T E[Ψ τ (ε * τ )],</formula><p>where</p><formula xml:id="formula_52">ε * τ = y * -X * β τ .</formula><p>A robust estimator of the covariance matrix is also proposed. Assume the following conditions.</p><p>B1. The data {(y i , X i )} n i=1 are independent across i and,</p><formula xml:id="formula_53">Var Ψ τ (ε * iτ )ε * iτ = E Ψ τ (ε * iτ )ε * iτ ε * iτ T Ψ τ (ε * iτ ) = Σ * iτ ,</formula><p>where</p><formula xml:id="formula_54">ε * iτ = ε * iτ 1 T , . . . , ε * iτ q T T , ε * iτ k = (ε * i1τ k , . . . , ε * imτ k ) T , ε * ijτ k = y * ij -x * ij T β τ k and Ψ τ (ε * iτ ) = [diag(Ψ τ k (ε * iτ k ))] q k=1 .</formula><p>B2. The limiting forms of the following matrices are positive definite</p><formula xml:id="formula_55">D 0 (τ) = lim n→∞ (V ⊗ X * ) T E[Ψ τ (ε * τ )ε * τ ε * τ T Ψ τ (ε * τ )](V ⊗ X * )/nm. D 1 (τ) = lim n→∞ (I q ⊗ X * ) T E[Ψ τ (ε * τ )](V ⊗ X * )/nm</formula><p>B3. The norm of the regressors is bounded by a positive constant M, max 1≤i≤n 1≤j≤m</p><p>x * ij &lt; M.</p><p>Theorem 2. Suppose conditions B1-B3 are satisfied, and that n, m → ∞.</p><formula xml:id="formula_56">If E|ψ τ (ε * ijτ )| 4+ν &lt; ∆ &lt; ∞ and E|ε * ijτ | 4+ν &lt; ∆ &lt; ∞ then √ nm β τ -β τ d -→ N 0, D -1 1 (τ)D 0 (τ)D -1 1 (τ) .</formula><p>In order to use the ERFE estimator to make inference, an estimator of its covariance matrix is presented in Theorem 3. This will make it possible to construct large sample confidence intervals or hypothesis tests. The proposed covariance matrix estimator is robust and consistent, and is a generalization of the commonly advocated covariance matrix estimator proposed by <ref type="bibr" target="#b25">White (1980)</ref>.</p><p>Theorem 3. Let the matrices D 0 (τ) and D 1 (τ) defined as:</p><formula xml:id="formula_57">D 0 (τ) = 1 nm (V ⊗ X * ) T Ψ τ ( ε * τ ) ε * τ ε * τ T Ψ τ ( ε * τ )(V ⊗ X * ), D 1 (τ) = 1 nm (I q ⊗ X * ) T Ψ τ ( ε * τ )(V ⊗ X * ),</formula><p>where the transformed data is obtained by pre-multiplying the initial data with the projection matrix M Z (τ) = I nmq -P Z (τ) and</p><formula xml:id="formula_58">P Z (τ) = (v ⊗ Z) (v ⊗ Z) T Ψ τ ( ε * τ )(1 q ⊗ Z) -1 (1 q ⊗ Z) T Ψ τ ( ε * τ ).</formula><p>Then, for every fixed, τ we have:</p><formula xml:id="formula_59">D -1 1 (τ) D 0 (τ) D -1 1 (τ) p -→ D -1 1 (τ)D 0 (τ)D -1 1 (τ).</formula><p>We end this section with the result for a single τ.</p><p>Corollary 1. Let the matrices D 0 (τ) and D 1 (τ) defined as:</p><formula xml:id="formula_60">D 0 (τ) = 1 nm n ∑ i=1 X * i T Ψ τ ( ε * iτ ) ε * iτ ε * iτ T Ψ τ ( ε * iτ ) X * i , D 1 (τ) = 1 nm n ∑ i=1 X * i T Ψ τ ( ε * iτ ) X * i</formula><p>with the corresponding projection matrices</p><formula xml:id="formula_61">M Z (τ) = I N -P Z (τ) and P Z (τ) = Z(Z T Ψ τ ( ε * τ )Z) -1 Z T Ψ τ ( ε * τ ).</formula><p>Then, under the above conditions and for every fixed τ, we have</p><formula xml:id="formula_62">D -1 1 (τ) D 0 (τ) D -1 1 (τ) p -→ D -1 1 (τ)D 0 (τ)D -1 1 (τ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Simulations</head><p>In this section we conducted a simulation study to evaluate the performance of the ERFE estimator. We started by presenting the simulation design, then the metrics to evaluate the estimators and the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design</head><p>The random samples were generated from the following linear model:</p><formula xml:id="formula_63">y ij = x ij1 β 1 + x ij2 β 2 + α i + (1 + γx ij2 )ε ij , i ∈ {1, . . . , n} and j ∈ {1, . . . , m}.<label>(22)</label></formula><p>We considered two versions of model equation ( <ref type="formula" target="#formula_63">22</ref>) according to the heteroscedastic parameter γ ∈ {0, 3/10}. The value of γ = 0 corresponds to a location shift model (M 0 ) where the regressors are uncorrelated to the random error. The model (M 0 ) is used to assess the performance of the estimators for a homoscedastic scenario. In contrast, when the value of γ = 3/10, then there is a correlation between the predictor x 2 and the random error. In that case, the model is a location-scale shift model (M 3/10 ) and is set to assess the performance of the estimators in the presence of heteroscedasticity.</p><p>In the location shift scenario, the ERFE model corresponds to</p><formula xml:id="formula_64">µ τ (y ij ) = x ij1 β 1 + x ij2 β 2 + α i + µ τ (ε ij )</formula><p>where only the intercept term, β 0τ = α i + µ τ (ε ij ), varies with τ and the expectile functions are parallel lines. In the location-scale shift scenario, the related ERFE model is defined</p><formula xml:id="formula_65">as: µ τ (y ij ) = x ij1 β 1 + x ij2 β 2τ + α i + µ τ (ε ij ) where the intercept β 0τ = α i + µ τ (ε ij ) and β 2τ = β 2 + γµ τ (ε ij ).</formula><p>Therefore, in the presence of heteroscedasticity both the intercept and the slope of the predictor x 2 vary with τ.</p><p>The parameters are set to β 1 = 0.6 and β 2 = 1, and the corresponding regressors are generated from a non-central student distribution with 3 degree of freedom (T 2 (1.3)) and a normal distribution (N (2, 1.5)), respectively. The individual-specific effects parameter α is generated from a normal distribution (N (1, 1)), and is correlated (ρ = 0.5) to the predictor x 2 . Indeed, in real data applications it is more likely that omitted factors are correlated with regressors in the model. The random error ε of the model equation ( <ref type="formula" target="#formula_63">22</ref>) is generated from three different distributions: normal distribution (N (0, 1)), Student distribution (T 3 ) with 3 degrees of freedom, and chi-squared distribution (χ 2 3 ) with 3 degrees of freedom. We have set the sample size and the repeated measurements to n × m ∈ {100, 250, 500} × {5, 15, 30}. The extensive simulation was carried out with 400 replications. In each case the focus is on the regressor effects at the asymmetric points τ ∈ {0.1, 0.3, 0.5, 0.8, 0.9}.</p><p>All simulations were conducted using high performance computing clusters provided by Calcul Quebec and Compute Canada. All computations were performed with the R (v3.6.0) statistical programming language R Core Team (2021). The implemented R package erfe that comes with this manuscript is publicly available on GitHub at <ref type="url" target="https://github.com/AmBarry/erfe">https://github.com/AmBarry/erfe</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance measures</head><p>We compared our ERFE model to the quantile regression with fixed-effects (QRFE) model proposed by <ref type="bibr" target="#b15">Koenker (2004)</ref>. The QRFE model estimated the parameter of interest and the nuisance parameter of the model which could be computationally demanding as the sample size increased. We also considered the expectile regression model (ER) and the quantile regression model (QR), which ignored the individual fixed-effects parameter. Given that expectile and quantile of the same level τ were generally different, we carried out the appropriate conversions between the asymmetric points and the percentiles to ensure that the expectile-based regressions and the quantile-based regressions estimated the same statistics (that is quantiles and expectiles are identical). For example, the Gaussian quantiles of level τ = (0.33, 0.5, 0.67) are identical to the Gaussian expectiles of level τ = (0.25, 0.5, 0.75). In other words, the ER based-model and the QR based-model estimate the same locations of the response distribution.</p><p>We evaluated the quality of the estimators by reporting the distribution of their coefficient estimate as box-plots. We also evaluated the performance of the asymptotic standard error (SE) presented in Theorem 3 by reporting the distribution of the ratio between the asymptotic standard error (SE) and the Monte Carlo standard deviation (SD) defined as:</p><formula xml:id="formula_66">SD 2 (β kτ ) = 1 400 400 ∑ j=1 β (j) kτ -β kτ 2 , k ∈ {1, 2},</formula><p>where</p><formula xml:id="formula_67">β kτ = 1 400 ∑ 400 j=1 β (j) kτ .</formula><p>We estimated the ERFE model with the erfe package and the QRFE model with the rqpd package <ref type="bibr" target="#b17">(Koenker and Bache, 2014)</ref>. The ER model and the QR model was obtained from the well-known packages: expectreg <ref type="bibr" target="#b23">(Sobotka et al., 2014)</ref> and quantreg <ref type="bibr" target="#b16">(Koenker, 2018)</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We present here the results related to the Gaussian random error and we brought the results</p><p>for the Student and Chi-square random errors in the Supplementary file. In the location-shift scenario, we observe that the coefficient estimates of our ERFE model are centered around the true value of the parameters with a small interquartile range. We also observe that the coefficient estimate of the ER and QR models are centered around the true value for the parameter β 1 only. We notice that the coefficient estimates of the QRFE model are not close to the true value of the parameters except when τ = 0.5 for the parameter β 1 only. In other words our ERFE model performs well in estimating the parameter coefficients of the model in the locationshift scenario. The ER and QR models perform similarly in the location-shift scenario, with an unbiased estimator for the parameter β 1 and a biased estimator for the parameter β 2 . The ER and QR models do not account for the individual fixed-effects which are correlated to the regressor</p><p>x 2 , which could explain the bias for the parameter β 2 . In contrast, the QRFE model performed poorly in estimating the parameter coefficients of the model in the location-shift scenario. The QRFE model includes the individual fixed-effects in its specification but, similarly to the randomeffect model, it did not account for the dependence between the individual fixed-effects and the regressors of the model. This could explained the poor performance of the QRFE .</p><p>Indeed, similar to the within-estimator, the ERFE model transforms the data by subtracting the person-specific expectile of level τ from the observed values of each variable and then applied the ER method to the de-expectilized model given by:</p><formula xml:id="formula_68">y * ij = x * ij1 β 1 + x * ij2 β 2 + ε * ij , (<label>23</label></formula><formula xml:id="formula_69">)</formula><p>where</p><formula xml:id="formula_70">y * ij = y ij -µ τ (y ij ),</formula><p>x * ij and ε * ij are defined similarly. This transformation concentrated out the individual fixed-effects and any bias that could result from its association with the regressors.</p><p>The ER and QR models do not take into account the individual fixed-effects parameter, which is included in the random error component. Since, the individual fixed-effects parameter is correlated to the predictor x 2 , then the random error of the model equation ( <ref type="formula" target="#formula_63">22</ref>) is also correlated to the predictor x 2 of the model. Hence, the coefficient estimate of the ER and QR methods for the parameter β 2 is biased.</p><p>Consider, the reformulation of model equation ( <ref type="formula" target="#formula_63">22</ref>) in the location-shift scenario:</p><formula xml:id="formula_71">y ij = x ij1 β 1 + x ij2 β 2 + Q τ (α i |x ij1 , x ij2 ) + (α i -Q τ (α i |x ij1 , x ij2 )) + ε ij = x ij1 β 1 + x ij2 β 2 + Q τ (α i |x ij1 , x ij2 ) + η ij , η ij = (α i -Q τ (α i |x ij1 , x ij2 )) + ε ij , where Q τ (α i |x ij1 , x ij2</formula><p>) is the quantile of the individual fixed-effects α i of level τ and η ij the new random variable. The corresponding QRFE model, for a fixed τ, can be specified as:</p><formula xml:id="formula_72">Q τ (y ij |x ij1 , x ij2 ) = x ij1 β 1 + x ij2 β 2 + f (x ij1 , x ij2 ), where f (x ij1 , x ij2 ) = Q τ (α i |x ij1 , x ij2</formula><p>) (since the individual fixedeffects are correlated to the regressors). Thus, in this context, the coefficient estimates of the QRFE model would be biased. Again, we observe that the ERFE model performs well in estimating the parameter coefficients of the model and outperformed its competitors. The apparent bias of the ERFE estimator for the parameter β 2 is due to the effect of the heteroscedasticity in this formulation of the model and is not surprising. Indeed, in the location-scale-shift scenario, because of the correlation between the predictor x 2 and the error term, the parameter of the predictor x 2 is function of the asymmetric point and then different to β 2 except when τ = 0.5 for the symmetric distributions (Normal and Student), where the expectile of level τ = 0.5 is zero. The same remark could be applied to the other methods which in addition did not account for the individual fixed-effects (ER and QR)</p><p>or its correlation with the regressors (QRFE). We observed similar results for the Student and Chi-square random errors (results are available in the Supplementary file).</p><p>Overall, the ERFE model outperforms its competitor and extends the favorable properties of the fixed-effects model. The ERFE model accounts for the time-invariant omitted variables and for the heteroscedasticity present in the data.</p><p>To evaluate the asymptotic standard error (SE) of the ERFE parameter estimates, we use the Monte Carlo standard deviation (SD) as a benchmark and present the distribution of the ratio We end this section by comparing the run-times of the ER-based algorithms and the QR-based algorithms. We fitted the methods to a dataset (n = 300, m = 10) generated by a location-shift model with a Gaussian random error. We used the microbenchmark package <ref type="bibr" target="#b20">(Mersmann, 2019)</ref> with 100 replications to evaluate the computation time of the different algorithm. The results in Figure <ref type="figure" target="#fig_10">5</ref> show that the cross-sectional algorithms ER and QR are the fastest algorithms, and our ERFE algorithm is faster than the QRFE algorithm. We also performed the comparison for a larger sample size (n &gt; 2500), but the algorithm stopped due to a shortage of memory for the QRFE algorithm. This problem has also been reported by <ref type="bibr" target="#b7">Canay (2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Application</head><p>Returns to schooling also known as returns to education is a topic widely studied in empirical economics. It is often presented in standard econometric textbooks <ref type="bibr" target="#b0">(Baltagi, 2008;</ref><ref type="bibr" target="#b13">Greene, 2011;</ref><ref type="bibr" target="#b6">Cameron and Trivedi, 2005)</ref> as an example of an endogeneity model. Indeed, there is a potential correlation between individual's ability and the other regressors such as education. In the presence of endogeneity, the FE model is often preferred than other mean regression models for panel data. Despite the fact that it does not estimate the effect of the time-invariant regressors, the FE estimator is consistent even if the individual effects are correlated with the regressors of the model <ref type="bibr" target="#b0">(Baltagi, 2008)</ref>.</p><p>In this section, we replicated Baltagi and Khanti-Akom ( <ref type="formula">1990</ref> We fitted the ERFE model to the PSID dataset. In addition to the regressor effects on the average salary <ref type="bibr" target="#b0">(Baltagi, 2008;</ref><ref type="bibr" target="#b1">Baltagi and Khanti-Akom, 1990;</ref><ref type="bibr" target="#b10">Cornwell and Rupert, 1988)</ref>, the ERFE model captures the regressor effects on the entire wage distribution. Consequently, the ERFE model controls for the endogeneity resulting from unmeasured factors and captures the heterogeneity present in the data. The corresponding Mincer equation of the ERFE model, for a fixed τ ∈ (0, 1), is specified as:</p><formula xml:id="formula_73">µ τ (log(Wage ij ) * ) = β 1τ WKS * ij + β 2τ EXP * ij + β 3τ EXP 2 * ij + β 4τ UNION * ij + β 5τ IND * ij + β 6τ MS * ij + β 7τ OCC * ij + β 8τ SOUTH * ij + β 9τ SMSA * ij ,</formula><p>where the initial model is transformed to eliminate the individual effects.</p><p>We estimated the conditional expectiles of the log wage distribution using 91 asymmetric points (τ ∈ (0.05, 0.06, 0.07, . . . , 0.95)). We generated the confidence intervals using the asymptotic standard error of the ERFE model. For comparison, we also fitted the ER model, the QR model and the QRFE model. Notice that the covariance matrix of the QR-based method depends on the random error density function which add a computational burden and some numerical issues <ref type="bibr" target="#b9">(Chen et al., 2004;</ref><ref type="bibr" target="#b26">Yin and Cai, 2005;</ref><ref type="bibr" target="#b14">Kocherginsky et al., 2005)</ref>. We used a kernel estimate of the sandwich as proposed by <ref type="bibr" target="#b2">Barnett et al. (1991)</ref> to compute the standard error of the QR estimates and the generalized bootstrap of <ref type="bibr" target="#b4">Bose and Chatterjee (2003)</ref> to compute the standard error of the QRFE estimates. Moreover, since an expectile of level τ is not necessarily equal to a quantile of the same level, the comparison between the ER-based results and the QR-based results must be done globally. respect to the asymmetric points or percentiles suggesting the presence of heteroscedasticity in the data. For example, we observe that the parameter estimates of the UNION variable decrease with respect to the asymmetric points or percentiles suggesting that individuals with low salary have more advantage of being unionized than individuals with high salary. We also observe that the parameter estimates of some regressors may vary a little or not at all with respect to the asymmetric points, suggesting that the mean effect of these regressors would be enough to summarize their relationship with the response variable.</p><p>We also observe that the curves of the ER-based results are smoother than those from the QRbased method which seem to be more wiggly and unstable. Indeed, the QR-based results is more volatile and it is more difficult to identify an overall trend of the heterogeneity of the regressor effects. For example, the QRFE parameter estimates of the IND variable is decreasing between the percentiles 0.1 and 0.25, and then increasing between the percentiles 0.25 and 0.9.</p><p>Despite the similar trend, the parameter estimates of the different methods have different statistical properties. The coefficient estimates of the ER and QR have similar range and are biased upward. For example, the ER and QR coefficient estimates of the WKS variable fluctuate between 0.0025 and 0.005. While the QRFE coefficient estimates of the WKS variable vary between 0.06 and 0.07, 10 times higher than that of the ERFE parameter estimates. Therefore, the QRFE coefficient estimates is severely biased because of its inability to account for the correlation between the individual fixed-effects and some regressors in the model.</p><p>This results are in line with the simulation results, where we observed that the ER and the QR estimates have similar and lower bias than the QRFE estimates which have higher bias particularly when the individual fixed-effects is correlated to the regressors in the model.</p><p>In summary, the data analysis shows that some parameter estimates vary according to the asymmetric points or the percentiles. Therefore, we need to consider beyond the mean or median regression in order to capture the heterogeneity present in the data. The FE model, like other methods that estimate the mean effect, is not sufficient to analyze the returns to schooling because the impact of most of the regressors vary across the wage distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduced the ERFE model which inherits the attractive properties of the weighted asym- We derived the asymptotic properties of the ERFE estimator and suggest an estimator of its variance covariance matrix. We showed that the ERFE estimator is an iterative-within-transformation estimator. That is, the ERFE estimator can be derived by using iteratively the within-transformation strategy to concentrate out the incidental parameter from the model. The ERFE model is computationally efficient and easy to implement. See our GitHub for a free R package that simplifies the implementation (github.com/AmBarry/erfe).</p><p>The exhaustive simulations showed that the ERFE estimator outperformed its competitors, including the QRFE estimator in the location-shift and location-scale-shift scenarios. These results</p><p>are not surprising because our ERFE estimator inherits the properties of the within-estimator which is simply an ERFE estimator of level τ = 0.5. The real data application showed that some parameter estimates vary according to the asymmetric points signaling the presence of heteroscedasticity in the data. Therefore we need to go beyond the mean regression to capture unobserved heterogeneity of the data and provide an overview of the relationship between the regressors and the dependent variables for a better decision making.</p><p>Our ERFE model suffers from the same limitations as the FE model which corresponds to the ERFE model of level τ = 0.5. The ERFE model estimates only the effects of the time-variant regressors. The ERFE model ignores also the between-subject variations which can affect the efficiency of its standard error. The ERFE model is a weighted mean regression and as such it is sensitive to aberrant values. Fortunately, there is a large number of regression diagnostic tools available to mitigate their influence.</p><p>There are alternatives in the literature that have been proposed to circumvent the lack of inference for the time-invariant regressors <ref type="bibr" target="#b10">(Cornwell and Rupert, 1988;</ref><ref type="bibr" target="#b1">Baltagi and Khanti-Akom, 1990)</ref>, while keeping the favorable properties of the FE model. Future research should investigate the possibility of adapting these methods to the ERFE framework.</p><p>In addition to the research avenues mentioned above we are currently exploring different alternatives such as penalizing the individual fixed-effects parameter to solve the incidental parameter problem while allowing inference on the time-invariant regressors.  <ref type="figure" target="#fig_6">1a</ref>) and the parameter β 2 (Figure <ref type="figure" target="#fig_6">1b</ref>) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m = (5, 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-shift scenario.  <ref type="figure" target="#fig_7">2a</ref>) and the parameter β 2 (Figure <ref type="figure" target="#fig_7">2b</ref>) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m = (5, 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-scale-shift scenario.  <ref type="figure" target="#fig_15">3a</ref>) and the parameter estimate β 2 (Figure <ref type="figure" target="#fig_15">3b</ref>) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m = (5, 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-shift scenario.  <ref type="figure" target="#fig_16">4a</ref>) and the parameter estimate β 2 (Figure <ref type="figure" target="#fig_16">4b</ref>) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-scale-shift scenario.     The proof of Theorem ?? is adapted from a proof of ?. First, we present a philosophical approach and, secondly, a thorough one. We adopt a purely heuristic approach and ignore the complications introduced by the infinite dimensional nature of the incidental parameter. In the completed version, we explicitly concentrate out the incidental parameter before showing the asymptotic property of the parameter estimator of interest. The Lemma ?? establishes the equivalence between the two approaches.</p><p>Part 1. Let µ ijτ = x ij T β τ + z ij T α and consider the following objective function</p><formula xml:id="formula_74">R nm (δ) = n ∑ i=1 m ∑ j=1 ρ τ y ij -µ ijτ -z ij T δ 0 / √ m -x ij T δ 1 / √ nm -ρ τ {y ij -µ ijτ }. (1)</formula><p>The above objective function is a convex function of δ that is minimized by</p><formula xml:id="formula_75">δ =    δ 0 δ 1    =    √ m( α -α) √ nm( β τ -β τ )    . (<label>2</label></formula><formula xml:id="formula_76">)</formula><p>Our goal is to approximate R nm by a quadratic function with a unique minimizing value, and use results from ? to show that δ has the same asymptotic distribution of that minimizing value.</p><p>This quadratic approximation is mainly composed by the Taylor expansion of the expected value and by a linear approximation function.</p><p>Let</p><formula xml:id="formula_77">x ij = (z ij T , x ij T ) T , δ = (δ 0 T / √ m, δ 1 T / √ nm) T and ε ijτ = y ij -µ ijτ . The func- tion E(ρ τ (ε ijτ -x ij T δ) -ρ τ (ε ijτ )</formula><p>) is convex, twice continuously differentiable and reaches its minimum at δ = 0. It can be represented in the neighbourhood of δ = 0 as</p><formula xml:id="formula_78">E ρ τ (ε ijτ -x ij T δ) -ρ τ (ε ijτ ) = δ T x ij E[ψ τ (ε ijτ )] x ij T δ -2 δ T x ij E[ψ τ (ε ijτ ).ε ijτ ] + o δ 2 , (<label>3</label></formula><formula xml:id="formula_79">)</formula><p>where</p><formula xml:id="formula_80">ψ τ (λ) = τ -1(λ &lt; 0). Since argmin δ ∈ R n+p E ρ τ (ε ijτ -x ij T δ) -ρ τ (ε ijτ ) = 0</formula><p>we have by the first order condition</p><formula xml:id="formula_81">E[ψ τ (ε ijτ ).ε ijτ ] = 0,<label>(4)</label></formula><p>and equation ( <ref type="formula" target="#formula_78">3</ref>) can be reduced to:</p><formula xml:id="formula_82">E ρ τ (ε ijτ -x ij T δ) -ρ τ (ε ijτ ) = δ T x ij E[ψ τ (ε ijτ )] x ij T δ + o δ 2 . (<label>5</label></formula><formula xml:id="formula_83">)</formula><p>The linear approximation function can be seen as a sort of Taylor expansion of R nm (δ) around δ = 0, see (?). Define</p><formula xml:id="formula_84">D ij (ε ijτ ) = -2ψ τ (ε ijτ ).ε ijτ . (<label>6</label></formula><formula xml:id="formula_85">)</formula><p>Notice that by ( <ref type="formula" target="#formula_4">4</ref>), E(D ij (ε ijτ )) = 0. Define</p><formula xml:id="formula_86">r ij ( δ) = ρ τ (ε ijτ -x ij T δ) -ρ τ (ε ijτ ) -δ T x ij D ij (ε ijτ ). Then R nm ( δ) = n ∑ i=1 m ∑ j=1 E ρ τ (ε ijτ -x ij T δ) -ρ τ (ε ijτ ) + n ∑ i=1 m ∑ j=1 δ T x ij D ij (ε ijτ ) + n ∑ i=1 m ∑ j=1 r ij ( δ) -E r ij ( δ) .</formula><p>Using Lemma ??, the objective function R nm ( δ) reduce to</p><formula xml:id="formula_87">R nm ( δ) = δ T n ∑ i=1 m ∑ j=1 x ij E[ψ τ (ε ijτ )] x ij T δ + δ T n ∑ i=1 m ∑ j=1 x ij D ij (ε ijτ ) + O δ 2 + o δ 2 = δ T n ∑ i=1 m ∑ j=1 x ij E[ψ τ (ε ijτ )] x ij T δ + δ T n ∑ i=1 m ∑ j=1 x ij D ij (ε ijτ ) + o p (1) δ T n ∑ i=1 m ∑ j=1 x ij E[ψ τ (ε ijτ )] x ij T δ + δ T n ∑ i=1 m ∑ j=1 x ij D ij (ε ijτ ). (<label>7</label></formula><formula xml:id="formula_88">)</formula><p>By replacing</p><formula xml:id="formula_89">x ij = (z ij T , x ij T ) T and δ = (δ 0 T / √ m, δ 1 T / √ nm)</formula><p>T by their initial value, we have</p><formula xml:id="formula_90">R nm (δ) = -2 1 √ m n ∑ i=1 m ∑ j=1 (z ij T δ 0 + x ij T δ 1 / √ n)ψ τ (y ij -µ ijτ ).(y ij -µ ijτ ) + 1 m n ∑ i=1 m ∑ j=1 E[ψ τ (y ij -µ ijτ )](z ij T δ 0 + x ij T δ 1 / √ n) 2 = -2 1 √ m δ 0 T Z T Ψ τ (ε τ )ε τ + δ 1 T / √ nX T Ψ τ (ε τ )ε τ + 1 m δ 0 T Z T E[Ψ τ (ε τ )]Zδ 0 + 2δ 0 T Z T E[Ψ τ (ε τ )]Xδ 1 / √ n + δ 1 T X T E[Ψ τ (ε τ )]Xδ 1 /n = R (1) nm (δ) + R (2) nm (δ)</formula><p>The condition A2 and A3 imply a Lindberg condition and we have</p><formula xml:id="formula_91">R (1) nm (δ) = -2 1 √ m δ 0 T Z T + δ 1 T / √ nX T Ψ τ (ε τ )ε τ d -→ -2δ T B.</formula><p>While by condition A2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R</head><p>(2)</p><formula xml:id="formula_92">nm (δ) = 1 m δ 0 T Z T E[Ψ τ (ε τ )]Zδ 0 + 2δ 0 T Z T E[Ψ τ (ε τ )]Xδ 1 / √ n + δ 1 T X T E[Ψ τ (ε τ )]Xδ 1 /n → δ T D 1 δ.</formula><p>Thus the limiting form of the objective function is</p><formula xml:id="formula_93">R 0 (δ) = -2δ T B + δ T D 1 δ</formula><p>where B is a zero mean Gaussian vector with covariance matrix D 0 . The objective function R nm is convex and its limiting form R 0 has a unique minimum. Therefore, by Theorem??, δ converge to the argmin of R 0 .</p><p>Part 2. In the precedent proof we overlook the complications related to the infinite dimensional nature of α. ?, following (??), used the Bahadur-Kiefer representation of the incidental parameter in order to concentrate out its effect and express the objective function solely in terms of the finite dimensional parameter β. With the smoothness of the asymmetric least square loss, we can use the first order condition to represent the incidental parameter as a function of the structural parameter.</p><p>Consider the following objective function</p><formula xml:id="formula_94">R nm (δ) = -2 1 √ m n ∑ i=1 m ∑ j=1 (z ij T δ 0 + x ij T δ 1 / √ n)ψ τ (y ij -µ ijτ ).(y ij -µ ijτ ) + 1 m n ∑ i=1 m ∑ j=1 E[ψ τ (y ij -µ ijτ )](z ij T δ 0 + x ij T δ 1 / √ n) 2 .</formula><p>This function is twice derivable and the first order condition gives us the exact representation of the incidental parameter</p><formula xml:id="formula_95">δ 0i √ m = 1 mψ i m ∑ k=1 ψ τ (y ik -µ ikτ )(y ik -µ ikτ ) - 1 mψ i m ∑ k=1 E ψ τ (y ik -µ ikτ ) x ik T δ 1 √ nm ,</formula><p>where</p><formula xml:id="formula_96">ψ i = m -1 ∑ m k=1 E ψ τ y ik -µ ikτ . Substituting δ 0i √ m we have δ 1 √ mn = n ∑ i=1 m ∑ j=1 x ij E[ψ τ (y ij -µ ijτ )] x ij T - 1 mψ i m ∑ k=1 E ψ τ (y ik -µ ikτ ) x ik T -1 × n ∑ i=1 m ∑ j=1 x ij ψ τ (y ij -µ ijτ )(y ij -µ ijτ ) - n ∑ i=1 m ∑ j=1 x ij E[ψ τ (y ij -µ ijτ )] 1 mψ i m ∑ k=1 ψ τ (y ik -µ ik )(y ik -µ ik ) . Note that, n ∑ i=1 m ∑ j=1 x ij E[ψ τ (y ij -µ ijτ )] x ij T - 1 mψ i m ∑ k=1 E ψ τ (y ik -µ ik ) x ik T = X T E[Ψ τ (ε τ )]X -X T P Z T E[Ψ τ (ε τ )]X = X T [I -P Z ] E[Ψ τ (ε τ )]X = X T M Z T E[Ψ τ (ε τ )]X = X T M Z T M Z T E[Ψ τ (ε τ )]X = X T M Z T E[Ψ τ (ε τ )]M Z X and n ∑ i=1 m ∑ j=1 x ij ψ τ (y ij -µ ijτ )(y ij -µ ijτ ) - n ∑ i=1 m ∑ j=1 x ij E[ψ τ (y ij -µ ijτ )]× 1 mψ i m ∑ k=1 ψ τ (y ik -µ ikτ )(y ik -µ ikτ ) = X T Ψ τ (ε τ )ε τ -X T P Z T Ψ τ (ε τ )ε τ = X T M Z T Ψ τ (ε τ )ε τ .</formula><p>Consequently,</p><formula xml:id="formula_97">δ 1 √ mn = X T M Z T E[Ψ τ (ε τ )]M Z X -1 X T M Z T Ψ τ (ε τ )ε τ = X T M Z T E[Ψ τ (ε τ )]M Z X/m -1 m -1 X T M Z T Ψ τ (ε τ )ε τ . (8) Let X Z = M Z X then we have m -1 X Z T Ψ τ (ε τ )ε τ = ∑ n i=1 ∑ m j=1 x ijZ ψ τ (ε ijτ )ε ijτ /m. Let T ni = ∑ m j=1 m -1 λ T x ijZ ψ τ (ε ijτ )ε ijτ and consider n -1/2 ∑ n i=1 T ni ,</formula><p>where λ is a p × 1 unit vector, λ T λ = 1. The summands T ni are independent with E[T ni ] = 0 and Var n -1/2 ∑ n i=1 T ni &gt; ν &gt; 0, by condition A2. By application of the Minkowski's inequality, we have</p><formula xml:id="formula_98">E|T ni | 2+ν = E m ∑ j=1 p ∑ k=1 m -1 λ k x k ijZ ψ τ (ε ijτ )ε ijτ 2+ν ≤ m ∑ j=1 p ∑ k=1 E m -1 λ k x k ijZ ψ τ (ε ijτ )ε ijτ 2+ν 1 2+ν 2+ν ≤ m ∑ j=1 p ∑ k=1 m -1 |λ k x k ijZ | E ψ τ (ε ijτ )ε ijτ 2+ν 1 2+ν 2+ν ≤ M∆p 1+ν ,</formula><p>where the last inequality follows by E|ψ τ (ε ijτ )| 4+ν &lt; ∆ and E|ε ijτ | 4+ν &lt; ∆.</p><p>Then by the Liapounov CLT X T M Z T Ψ τ (ε τ )ε τ is Gaussian and by condition A2, δ 1 is zero mean Gaussian vector with covariance matrix Var(</p><formula xml:id="formula_99">β τ ) = D -1 1 D 0 D -1 1 .</formula><p>Proof of Lemma ??.</p><p>we intend to show that this new covariance matrix D -1</p><formula xml:id="formula_100">1 D 0 D -1</formula><p>1 is identical to the lower right</p><formula xml:id="formula_101">diagonal block matrix D -1 1 D 0 D -1 1 .</formula><p>We have</p><formula xml:id="formula_102">(D -1 1 D 0 D -1 1 ) 22 = (D -1 1 ) 2. D 0 (D -1 1 ) 2.</formula><p>T . Using the standard partitioned inverse formula for a general 2 × 2 partitioned matrix, we have</p><formula xml:id="formula_103">mn(D -1 1 D 0 D -1 1 ) 22 = -FE -1 E -1    Z T Σ τ Z Z T Σ τ X X T Σ τ Z X T Σ τ X       -FE -1 E -1    = E -1 [F T Z T Σ τ ZF -X T Σ τ ZF -F T Z T Σ τ X + X T Σ τ X]E -1 where E = X T E[Ψ τ (ε τ )]X -X T E[Ψ τ (ε τ )]Z(Z T E[Ψ τ (ε τ )]Z) -1 Z T E[Ψ τ (ε τ )]X = mn D 1 , and ZF = Z(Z T E[Ψ τ (ε τ )]Z) -1 Z T E[Ψ τ (ε τ )]X = P Z X.</formula><p>The term in square brackets is</p><formula xml:id="formula_104">F T Z T Σ τ ZF -X T Σ τ ZF -F T Z T Σ τ X + X T Σ τ X = X T P Z T Σ τ P Z X -X T Σ τ P Z X -X T P Z T Σ τ X + X T Σ τ X = X T [P Z T Σ τ P Z -Σ τ P Z -P Z T Σ τ + Σ τ ]X = X T [I -P Z T ]Σ τ [I -P Z ]X = X T M Z T Σ τ M Z X = D 0 .</formula><p>Finally, the result follows.</p><p>Proof of Theorem ??.</p><p>In the following, we remove the asterix as an exponent to lighten the notation. Using the same approach to the proof of Theorem ??, the objective function R mnq (δ) can be decomposed into two parts</p><formula xml:id="formula_105">R mnq (δ) = R<label>(1)</label></formula><formula xml:id="formula_106">mnq (δ) + R<label>(2)</label></formula><p>mnq (δ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R</head><p>(1)</p><formula xml:id="formula_107">nmq (δ) = -2 √ nm q ∑ k=1 n ∑ i=1 m ∑ j=1 v k δ τ k T x ij ψ τ k (ε ijτ k ).ε ijτ k = -2 √ nm q ∑ k=1 v k δ τ k T X T Ψ τ k (ε τ k )ε τ k = -2 √ nm δ T (V ⊗ X) T Ψ τ (ε τ )ε τ = -2 √ nm δ T       v 1 X T • • • 0 . . . . . . . . . 0 • • • v q X T             Ψ τ 1 (ε τ 1 ) • • • 0 . . . . . . . . . 0 • • • Ψ τ q (ε τ q )             ε τ 1 . . . ε τ q       = -2 √ nm δ T n ∑ i=1 (V ⊗ X i ) T Ψ τ (ε iτ )ε iτ = -2 √ nm δ T n ∑ i=1                     v 1 ∑ m j=1 x 1 ij ψ τ 1 (ε itτ 1 )ε itτ 1 . . . v 1 ∑ m j=1 x p ij ψ τ 1 (ε itτ 1 )ε itτ 1 . . . v q ∑ m j=1 x 1 ij ψ τ q (ε itτ q )ε itτ q . . . v q ∑ m j=1 x p ij ψ τ q (ε itτ q )ε itτ q                     d -→ -2δ T B.</formula><p>To show the asymptotic normality of B, we apply the Cramér-Wold device and verify the Lyapunov's condition.</p><p>Let</p><formula xml:id="formula_108">T ni = m -1 λ T (V ⊗ X i ) T Ψ τ (ε iτ )ε iτ and consider n -1/2 ∑ n i=1 T ni , where λ is a pq × 1 unit vec- tor, λ T λ = 1. The summands T ni are independent with E[T ni ] = 0 and Var n -1/2 ∑ n i=1 T ni &gt; ν &gt; 0, by condition A2.</formula><p>By the Minkowski's inequality, we have</p><formula xml:id="formula_109">E|T ni | 2+ν = E q ∑ k=1 p ∑ l=1 v k λ kl m ∑ j=1 m -1 x l ij ψ τ k (ε ijτ k )ε ijτ k 2+ν = E q ∑ k=1 p ∑ l=1 m ∑ j=1 m -1 v k λ kl x l ij ψ τ k (ε ijτ k )ε ijτ k 2+ν ≤ q ∑ k=1 p ∑ l=1 m ∑ j=1 E m -1 v k λ kl x l ij ψ τ k (ε ijτ k )ε ijτ k 2+ν 1 2+ν 2+ν</formula><p>.</p><p>By the Cauchy-Schwarz inequality, we have</p><formula xml:id="formula_110">E m -1 v k λ kl x l ij ψ τ k (ε ijτ k )ε ijτ k 2+ν = |m -1 v k λ kl x l ij | 2+ν E ψ τ k (ε ijτ k )ε ijτ k 2+ν ≤ (m -1 M|λ kl |) 2+ν E|ψ τ k (ε ijτ k )| 4+ν 1/2 E|ε ijτ k | 4+ν 1/2 ≤ (m -1 M|λ kl |) 2+ν ∆,</formula><p>where the last inequality follows by</p><formula xml:id="formula_111">E|ψ τ k (ε ijτ k )| 4+ν &lt; ∆ and E|ε ijτ k | 4+ν &lt; ∆. Therefore, E|T ni | 2+ν ≤ q ∑ k=1 p ∑ l=1 m ∑ j=1 m -1 M|λ kl |∆ 1 2+ν 2+ν ≤ ∆M 2+ν |λ T 1 pq | 2+ν ≤ ∆(pq) 1+ν .</formula><p>Then by the Liapounov CLT B is a zero mean Gaussian vector with covariance matrix D 0 (τ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R</head><p>(2)</p><formula xml:id="formula_112">nmq (δ) = 1 nm q ∑ k=1 n ∑ i=1 m ∑ j=1 v k δ τ k T x ij E[ψ τ k (ε ijτ k )]x ij T δ τ k = 1 nm q ∑ k=1 v k δ τ k T X T E[Ψ τ k (ε τ k )]Xδ τ k → δ T D 1 (τ)δ.</formula><p>Thus the limiting form of the objective function is</p><formula xml:id="formula_113">R 0q (δ) = -2δ T B + δ T D 1 (τ)δ</formula><p>where B is a zero mean Gaussian vector with covariance matrix D 0 (τ). Application of Theorem 2.2 of ? gives the result of Theorem ??.</p><p>Proof of Theorem ??.</p><p>We have</p><formula xml:id="formula_114">D 1 (τ) = 1 nm (I q ⊗ X * ) T Ψ τ ( ε * τ )(V ⊗ X * ) = 1 nm n ∑ i=1 diag v 1 X * i T Ψ τ 1 ( ε * iτ 1 ) X * i , . . . , v q X * i T Ψ τ q ( ε * iτ q ) X * i .</formula><p>The convergence of D 1 (τ) is obtained by showing the convergence of the general term</p><formula xml:id="formula_115">1 nm ∑ n i=1 v k X * i T Ψ τ k ( ε * iτ k ) X * i .</formula><p>This general term breaks down as follows:</p><formula xml:id="formula_116">n ∑ i=1 X * i T Ψ τ ( ε * iτ ) X * i = X * T Ψ τ ( ε * τ ) X * = X T M Z (τ) T Ψ τ ( ε * τ ) M Z (τ)X = X T Ψ τ ( ε * τ ) M Z (τ)X = X T Ψ τ ( ε * τ )[I nm -P Z (τ)]X = X T Ψ τ ( ε * τ )X -X T Ψ τ ( ε * τ ) P Z (τ)X.<label>(9)</label></formula><p>We will show the convergence of each of the terms separately. First, consider the following expression:</p><formula xml:id="formula_117">|ψ τ ( ε * ijτ ) -ψ τ (ε * ijτ )|. This expression is 0 except when x * ij T β τ ≤ y * ij ≤ x * ij T β τ or x * ij T β τ ≤ y * ij ≤ x * ij T β τ .</formula><p>It can be bounded as follows:</p><formula xml:id="formula_118">|ψ τ ( ε * ijτ ) -ψ τ (ε * ijτ )| ≤ |1 -2τ|1 |ε * ijτ | ≤ |x * ij T ( β τ -β τ )| ≤ |1 -2τ|1 |ε * ijτ | ≤ x * ij β τ -β τ ≤ |1 -2τ|1 |ε * ijτ | ≤ pM β τ -β τ .<label>(10)</label></formula><p>As plim β τ = β τ , we have, by equation ( <ref type="formula" target="#formula_13">10</ref>) and Markov's inequality:</p><formula xml:id="formula_119">(nm) -1 X T [Ψ τ ( ε * τ ) -Ψ τ (ε * τ )]X = (nm) -1 n ∑ i=1 X i T [Ψ τ ( ε * iτ ) -Ψ τ (ε * iτ )]X i p -→ 0.</formula><p>In other words:</p><formula xml:id="formula_120">(nm) -1 X T Ψ τ ( ε * τ )X = (nm) -1 X T Ψ τ (ε * τ )X + o p (1).<label>(11)</label></formula><p>This result ( <ref type="formula" target="#formula_15">11</ref>) is important and will be used frequently below. Another useful result is the convergence of the function w * iτ = (∑ m j=1 ψ τ ( ε * ijτ )) -1 which appears in the expression of P Z (τ). This function is bounded by:</p><formula xml:id="formula_121">m min(τ, 1 -τ) ≤ w * -1 iτ ≤ m max(τ, 1 -τ).</formula><p>We have</p><formula xml:id="formula_122">1 nm n ∑ i=1 w * iτ - 1 nm n ∑ i=1 E[w * iτ ] ≤ 1 nm n ∑ i=1 w * iτ - 1 nm n ∑ i=1 E[w * iτ ] + 1 nm n ∑ i=1 w * iτ - 1 nm n ∑ i=1 w * iτ .<label>(12)</label></formula><p>The first term converges by Markov's Law of Large Numbers (LLN). The second term is bounded by:</p><formula xml:id="formula_123">1 nm n ∑ i=1 w * iτ - 1 nm n ∑ i=1 w * iτ ≤ 1 nm 3 n ∑ i=1 m ∑ j=1 |ψ τ ( ε * ijτ ) -ψ τ (ε * ijτ )|.</formula><p>Thus, convergence is achieved by the application of (10). Now, let's show the convergence of the first term on the last line of equation ( <ref type="formula" target="#formula_11">9</ref>). We have:</p><formula xml:id="formula_124">1 nm n ∑ i=1 X i T Ψ τ ( ε * iτ )X i - 1 nm n ∑ i=1 X i T E[Ψ τ (ε * iτ )]X i ≤ 1 nm n ∑ i=1 X i T [Ψ τ ( ε * iτ ) -Ψ τ (ε * iτ )]X i + 1 nm n ∑ i=1 X i T Ψ τ (ε * iτ )X i - 1 nm n ∑ i=1 X i T E[Ψ τ (ε * iτ )]X i .<label>(13)</label></formula><p>The result (11) gives the convergence of the first term on the right of the inequality and the application of Markov's Law of large-number (LLN) gives the convergence of the second term.</p><p>The second term on the last line of equation ( <ref type="formula" target="#formula_11">9</ref>) is expressed by:</p><formula xml:id="formula_125">X T Ψ τ ( ε * τ ) P Z (τ)X = n ∑ i=1 m ∑ j=1 m ∑ k=1 w * iτ ψ τ ( ε * ijτ )ψ τ ( ε * ikτ )x ij x ik T . (<label>14</label></formula><formula xml:id="formula_126">)</formula><p>We will use the following relation to show its convergence</p><formula xml:id="formula_127">w * iτ ψ τ ( ε * ijτ )ψ τ ( ε * ikτ ) -w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ ) = ( w * iτ -w * iτ )ψ τ ( ε * ijτ )ψ τ ( ε * ikτ ) + w * iτ ψ τ ( ε * ijτ )[ψ τ ( ε * ikτ ) -ψ τ (ε * ikτ )] + ψ τ (ε * ikτ )[ψ τ ( ε * ijτ ) -ψ τ (ε * ijτ )] .<label>(15)</label></formula><p>To show the convergence of the expression ( <ref type="formula" target="#formula_21">14</ref>), consider:</p><formula xml:id="formula_128">1 nm n ∑ i=1 m ∑ jk x ij x ik T w * iτ ψ τ ( ε * ijτ )ψ τ ( ε * ikτ ) - 1 nm n ∑ i=1 m ∑ jk x ij x ik T E[w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ )] ≤ 1 nm n ∑ i=1 m ∑ jk x ij x ik T [ w * iτ ψ τ ( ε * ijτ )ψ τ ( ε * ikτ ) -w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ )] + 1 nm n ∑ i=1 m ∑ jk x ij x ik T w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ ) - 1 nm n ∑ i=1 m ∑ jk x ij x ik T E[w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ )] ≤ 1 nm n ∑ i=1 m ∑ jk x ij x ik T ( w * iτ -w * iτ )ψ τ ( ε * ijτ )ψ τ ( ε * ikτ ) + 1 nm n ∑ i=1 m ∑ jk x ij x ik T w * iτ ψ τ ( ε * ijτ )[ψ τ ( ε * ikτ ) -ψ τ (ε * ikτ )] + ψ τ (ε * ikτ )[ψ τ ( ε * ijτ ) -ψ τ (ε * ijτ )] + 1 nm n ∑ i=1 m ∑ jk x ij x ik T w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ ) - 1 nm n ∑ i=1 m ∑ jk x ij x ik T E[w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ )] ≤ 1 nm n ∑ i=1 m ∑ jk x ij x ik T ( w * iτ -w * iτ ) + 1 nm 2 n ∑ i=1 m ∑ jk x ij x ik T [ψ τ ( ε * ikτ ) -ψ τ (ε * ikτ )] + 1 nm 2 n ∑ i=1 m ∑ jk x ij x ik T [ψ τ ( ε * ijτ ) -ψ τ (ε * ijτ )] + 1 nm n ∑ i=1 m ∑ jk x ij x ik T w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ ) - 1 nm n ∑ i=1 m ∑ jk x ij x ik T E[w * iτ ψ τ (ε * ijτ )ψ τ (ε * ikτ )] .<label>(16)</label></formula><p>Finally, the convergence of the expression ( <ref type="formula" target="#formula_21">14</ref>) results from the application of the relations ( <ref type="formula" target="#formula_15">11</ref>) and ( <ref type="formula" target="#formula_17">12</ref>) and from the application of Markov's Law of Large Numbers.</p><p>The second term of the variance-covariance matrix whose convergence we must show is:</p><formula xml:id="formula_129">D 0 (τ) = 1 nm (V ⊗ X * ) T Ψ τ ( ε * τ ) ε * τ ε * τ T Ψ τ ( ε * τ )(V ⊗ X * ), = 1 nm n ∑ i=1       v 2 1 X * i T Σ * iτ 1 τ 1 X * i • • • • • • v 1 v q X * i T Σ * iτ 1 τ q X * i . . . . . . . . . . . . v 1 v q X * i T Σ * iτ q τ 1 X * i • • • • • • v 2 q X * i T Σ * iτ q τ q X * i      </formula><p>where</p><formula xml:id="formula_130">Σ * iτ k τ j = Ψ τ k ( ε * iτ k ) ε * iτ k ε * iτ j T Ψ τ j ( ε * iτ j ).</formula><p>Again, showing the convergence of the general term suffices:</p><formula xml:id="formula_131">1 nm n ∑ i=1 X * i T Σ * iτ k τ j X * i = 1 nm X * T Ψ τ k ( ε * τ k ) ε * τ k ε * τ j T Ψ τ j ( ε * τ j ) X *<label>(17)</label></formula><p>Note that,</p><formula xml:id="formula_132">ε * τ = ε * τ -X * ( β τ -β τ ) + ∆M Z (τ)[y -X β τ ],</formula><p>where ∆M Z (τ) = M Z (τ) -M Z (τ) = P Z (τ) -P Z (τ) = ∆P Z (τ). We have,</p><formula xml:id="formula_133">ε τ * τ k ε τ * τ j T = ε * τ k ε * τ j T -ε * τ k ( β τ j -β τ j ) T X * T + ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T -X * ( β τ k -β τ k )ε * τ j T + X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T -X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T + ∆P Z (τ k )[y -X β τ k ]ε * τ j T -∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T + ∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T</formula><p>Then, replacing X * = M Z (τ)X = X * + ∆M Z (τ)X, we obtain:</p><formula xml:id="formula_134">X * T Ψ τ k ( ε * τ k ) ε * τ k ε * τ j T Ψ τ j ( ε * τ j ) X * = + X * T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )X * -X * T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * + X * T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )X * + X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )X * -X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * + X * T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X * T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X * T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )X * -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )X * + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X *</formula><p>(continued on next page) (continued from previous page)</p><formula xml:id="formula_135">-X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )X * -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X.</formula><p>Now let's break down the following expression:</p><formula xml:id="formula_136">X * T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )X * = X * T Ψ τ k (ε * τ k )ε * τ k ε * τ j T Ψ τ j (ε * τ j )X * + X * T Ψ τ k (ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j ) -Ψ τ j (ε * τ j ) X * + X * T Ψ τ k ( ε * τ k ) -Ψ τ k (ε * τ k ) ε * τ k ε * τ j T Ψ τ j (ε * τ j )X * + X * T Ψ τ k ( ε * τ k ) -Ψ τ k (ε * τ k ) ε * τ k ε * τ j T Ψ τ j ( ε * τ j ) -Ψ τ j (ε * τ j ) X * .</formula><p>The final expression of ( <ref type="formula" target="#formula_26">17</ref>) is:</p><formula xml:id="formula_137">X * T Ψ τ k ( ε * τ k ) ε * τ k ε * τ j T Ψ τ j ( ε * τ j ) X * = + X * T Ψ τ k (ε * τ k )ε * τ k ε * τ j T Ψ τ j (ε * τ j )X * (e1) + X * T Ψ τ k (ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j ) -Ψ τ j (ε * τ j ) X * (e2) + X * T Ψ τ k ( ε * τ k ) -Ψ τ k (ε * τ k ) ε * τ k ε * τ j T Ψ τ j (ε * τ j )X * (e3) + X * T Ψ τ k ( ε * τ k ) -Ψ τ k (ε * τ k ) ε * τ k ε * τ j T Ψ τ j ( ε * τ j ) -Ψ τ j (ε * τ j ) X * (e4) -X * T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * (e5) + X * T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * (e6) -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )X * (e7) + X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * (e8) -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * (e9) + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )X * (e10) -X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * (e11) + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * (e12) + X * T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e13) -X * T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e14) + X * T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e15) -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e16) + X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e17) -X * T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e18) + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e19) -X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e20) + X * T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X<label>(e21)</label></formula><p>(continued on next page) (continued from previous page)</p><formula xml:id="formula_138">+ X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )X * (e22) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * (e23) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * (e24) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )X * (e25) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * (e26) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * (e27) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )X * (e28) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )X * (e29) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )X * (e30) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e31) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k ( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e32) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )ε * τ k [y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e33) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X<label>(e34)</label></formula><p>(continued on next page) (continued from previous page)</p><formula xml:id="formula_139">+ X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e35) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )X * ( β τ k -β τ k )[y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e36) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]ε * τ j T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e37) -X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ]( β τ j -β τ j ) T X * T Ψ τ j ( ε * τ j )∆P Z (τ j )X (e38) + X T ∆P Z (τ k ) T Ψ τ k ( ε * τ k )∆P Z (τ k )[y -X β τ k ][y -X β τ j ] T ∆P Z (τ j ) T Ψ τ j ( ε * τ j )∆P Z (τ j )X. (<label>e39</label></formula><formula xml:id="formula_140">)</formula><p>The demonstration is based on showing the convergence of each of these terms (e2)-(e39). We have three types of expression: those that are function of ∆P Z , those that are function of</p><formula xml:id="formula_141">Ψ τ k ( ε * τ k ) - Ψ τ k (ε * τ k )</formula><p>and those that are function of ( β τ jβ τ j ). Those that are a function of ∆P Z are shown by following the approach of ( <ref type="formula" target="#formula_17">12</ref>) and those that are function of</p><formula xml:id="formula_142">Ψ τ k ( ε * τ k ) -Ψ τ k (ε * τ k )</formula><p>according to the approach (11). The convergence technique of those that are a function of ( β τ jβ τ j ) is identical to the convergence procedure used for (e7) and (e8). Thus, in the following, we will show the convergence of (e7) and (e8).</p><p>Using the relation, Vec(ABC) = (C T ⊗ A) Vec(B), equation (e7) is transformed as follows:</p><formula xml:id="formula_143">Vec 1 nm n ∑ i=1 X * i T Ψ τ k ( ε * iτ k )X * i ( β τ k -β τ k )ε * iτ j T Ψ τ j ( ε * iτ j )X * i = 1 nm n ∑ i=1 X * i T Ψ τ k ( ε * iτ k )ε * iτ j ⊗ X * i T Ψ τ j ( ε iτ j )X * i Vec( β τ k -β τ k ).</formula><p>Applying Lemma ??, we have</p><formula xml:id="formula_144">E X * i T Ψ τ k ( ε * iτ k )ε * iτ j ⊗ X * i T Ψ τ j ( ε iτ j )X * i 1+ν ≤ E X * i T Ψ τ k ( ε * iτ k )ε * iτ j 2+2ν E X * i T Ψ τ j ( ε iτ j )X * i 2+2ν 1/2 .</formula><p>Repeated application of Minkowski and Holder inequalities shows that</p><formula xml:id="formula_145">E X * i T Ψ τ k ( ε * iτ k )ε * iτ j 2+2ν = E p ∑ k=1 m ∑ j=1 x * k ij ψ τ k ( ε * ijτ k )ε * ijτ j 2 1+ν ≤ p ∑ k=1 E m ∑ j=1 x * k ij ψ τ k ( ε * ijτ k )ε * ijτ j 2+2ν 1 1+ν 1+ν ≤ p ∑ k=1 m ∑ j=1 E|x * k ij ψ τ k ( ε * ijτ k )ε * ijτ j | 2+2ν 1 2+2ν 2+2ν 1+ν ≤ (p∆) 1+ν (Mm) 2+ν .</formula><p>The last inequality is obtained by applying the assumptions E|ψ Considering that Vec( β τβ τ ) = O p ((nm) -1/2 ) and that</p><formula xml:id="formula_146">τ ( ε ijτ )| 4+ν &lt; ∆ and E|ε ijτ | 4+ν &lt; ∆. Similarly E X * i T Ψ τ j ( ε iτ j )X * i 2+2ν ≤ E X * i T Ψ 1/2 τ j ( ε iτ j ) 4+4ν ≤ p ∑ k=1 m ∑ j=1 E|(x * k ij ψ 1/2 τ j ( ε * ijτ j )) 2 | 2+2ν</formula><formula xml:id="formula_147">E X * i T Ψ τ k ( ε * iτ k )X * i 2+2ν &lt; (pm) 2+ν ∆, term (e8) is 1 nm Vec n ∑ i=1 X * i T Ψ τ k ( ε * iτ k )X * i ( β τ k -β τ k )( β τ j -β τ j ) T X * i T Ψ τ j ( ε * iτ j )X * i = 1 nm n ∑ i=1 X * i T Ψ τ j ( ε * iτ j )X * i ⊗ X * i T Ψ τ k ( ε * iτ k )X * i Vec[( β τ -β τ )( β τ k -β τ k ) T ] = 1 nm O p (1)O p (1).</formula><p>We have just shown that</p><formula xml:id="formula_148">1 nm n ∑ i=1 X * i T Σ * iτ k τ j X * i - 1 nm n ∑ i=1 X * i T Ψ τ k (ε * iτ k )ε * iτ k ε * iτ j T Ψ τ j (ε * iτ j )X * i p -→ 0.</formula><p>Application of the Markov LLN also yields</p><formula xml:id="formula_149">1 nm n ∑ i=1 X * i T Ψ τ k (ε * iτ k )ε * iτ k ε * iτ j T Ψ τ j (ε * iτ j )X * i - 1 nm n ∑ i=1 X * i T Σ * iτ k τ j X * i p -→ 0.</formula><p>Thus, application of the triangular inequality shows that D 0 (τ) p -→ D 0 (τ).</p><p>Proof of Corollary ??.</p><p>Proof of Corollary ?? follows immediately from the proof of Theorem ??.</p><p>2 Additional simulation results  <ref type="figure" target="#fig_7">2a</ref>) and the parameter β 2 (Figure <ref type="figure" target="#fig_7">2b</ref>) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ T (3) in the location-scale-shift scenario.  <ref type="figure" target="#fig_15">3a</ref>) and the parameter β 2 (Figure <ref type="figure" target="#fig_15">3b</ref>) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-shift scenario.  <ref type="figure" target="#fig_16">4a</ref>) and the parameter β 2 (Figure <ref type="figure" target="#fig_16">4b</ref>) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-scale-shift scenario.  <ref type="figure" target="#fig_17">5a</ref>) and the parameter estimate β 2 (Figure <ref type="figure" target="#fig_17">5b</ref>) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ T (3) in the location-shift scenario.  <ref type="figure" target="#fig_4">6a</ref>) and the parameter estimate β 2 (Figure <ref type="figure" target="#fig_18">6b</ref>) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ T (3) in the location-scale-shift scenario.  <ref type="figure" target="#fig_19">7a</ref>) and the parameter estimate β 2 (Figure <ref type="figure" target="#fig_19">7b</ref>) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-shift scenario.  <ref type="figure" target="#fig_20">8a</ref>) and the parameter estimate β 2 (Figure <ref type="figure" target="#fig_20">8b</ref>) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m = <ref type="bibr" target="#b12">(5,</ref><ref type="bibr">15,</ref><ref type="bibr">30)</ref>, the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-scale-shift scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ER</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>and Figure 2 report the distribution of the coefficient estimates in the location-shift and location-scale-shift scenarios, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 report the distribution of the coefficient estimates in the location-scale-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head/><label/><figDesc>SESD as an error plot centered at the mean, Figure3and Figure 4. In general the error plots of the ERFE model and the QRFE model are centered around 1, which means that on average the asymptotic standard error SE and the Monte Carlo standard deviation SD are identical. However, we observe that the error plots of the ER model and the QR model are not centered around the mean for the β 2 parameter and the range of their error plot is generally larger. Similar performances were observed for the Student and Chi-Squared random error which results can be found in the Supplementary file.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head/><label/><figDesc>)'s study using the Panel Study of Income Dynamics (PSID) dataset. The dataset is a cohort of 595 individuals observed over the period1976 -1982 . The respondents, aged between 18 and 65 in 1976, are those who reported a positive wage in private non-farm employment for all 7 years,<ref type="bibr" target="#b10">(Cornwell and Rupert, 1988)</ref>.The log wage is the dependent variable and is regressed on weeks worked (WKS), years of fulltime work experience (EXP), occupation (OCC=1, if the individual is in a blue-collar occupation), residence (SOUTH = 1, SMSA = 1, if the individual resides in the South, or in a standard metropolitan statistical area), marital status (MS = 1, if the individual is married), industry (IND = 1, if the individual works in a manufacturing industry), and union coverage (UNION = 1, if the individual's wage is set by a union contract).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6a and</head><label>6a</label><figDesc>Figure 6a and Figure 6b display the coefficient estimates of the regressors obtained by fitting the ER-based methods while Figure 7a and Figure 7b display the coefficient estimates of the regressors obtained by fitting the QR-based methods. The overall results show the potential of both ER-based and QR-based methods to reveal the heterogeneous regressor effects on the response distribution and therefore to capture the heteroscedasticity present in the data. We observe that the parameter estimates of some regressors (UNION, IND and SOUTH, for example) vary with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head/><label/><figDesc>metric least squares regression (ER) and the FE model. As with the FE model, the ERFE model is an endogenous model that takes into account the possible correlation between the omitted time-invariant variables and the regressors included in the model. In addition, the ERFE model estimates the regressor effects on the conditional expectiles of the response distribution allowing to study the influence of the regressors on the location, scale, and shape of the conditional response distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Distribution of the coefficient estimates of the parameter β 1 (Figure1a) and the parameter β 2 (Figure1b) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of the coefficient estimates of the parameter β 1 (Figure2a) and the parameter β 2 (Figure2b) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-scale-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Distribution of the ratio SESD for the parameter estimate β 1 (Figure3a) and the parameter estimate β 2 (Figure3b) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Distribution of the ratio SESD for the parameter estimate β 1 (Figure4a) and the parameter estimate β 2 (Figure4b) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ N (0, 1) in the location-scale-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Distribution of the computation time (in seconds) of the ER-based algorithms and the QR-based algorithms. The algorithms are fitted to a dataset (n = 300, m = 10) generated by a location-shift model with a Gaussian random error. All other settings are identical to those used in the simulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: ER and ERFE coefficient estimates. Fig. (a) displays coefficient estimates of the regressors: EXPSQ, EXP, UNION and WKS, with their estimated confidence intervals. Fig. (b) displays coefficient estimates of the regressors: IND, MS, OCC, SMSA and SOUTH, with their estimated confidence intervals. The EXPSQ variable is the square of the experience variable (EXP) and the log of wage is the dependent variable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: QR and QRFE coefficient estimates. Fig. (a) displays coefficient estimates of the regressors: EXPSQ, EXP, UNION and WKS, with their estimated confidence intervals. Fig. (b) displays coefficient estimates of the regressors: IND, MS, OCC, SMSA and SOUTH, with their estimated confidence intervals. The EXPSQ variable is the square of the experience variable (EXP) and the log of wage is the dependent variable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>T</head><label/><figDesc>Ψ τ k ( ε * iτ k )X * i ( β τ kβ τ k )ε * iτ j T Ψ τ j ( ε * iτ j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure1: Distribution of the coefficient estimates of the parameter β 1 (Figure1a) and the parameter β 2 (Figure1b) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ T (3) in the location-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Distribution of the coefficient estimates of the parameter β 1 (Figure3a) and the parameter β 2 (Figure3b) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Distribution of the coefficient estimates of the parameter β 1 (Figure4a) and the parameter β 2 (Figure4b) represented as boxplot according to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-scale-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Distribution of the ratio SESD for the parameter estimate β 1 (Figure5a) and the parameter estimate β 2 (Figure5b) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ T (3) in the location-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Distribution of the ratio SESD for the parameter estimate β 1 (Figure6a) and the parameter estimate β 2 (Figure6b) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ T (3) in the location-scale-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Distribution of the ratio SESD for the parameter estimate β 1 (Figure7a) and the parameter estimate β 2 (Figure7b) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-shift scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Distribution of the ratio SESD for the parameter estimate β 1 (Figure8a) and the parameter estimate β 2 (Figure8b) represented as an error plot with respect to the sample size n ∈ (100, 250, 500), the repeated measurements m =<ref type="bibr" target="#b12">(5,</ref> 15, 30), the asymmetric points τ ∈ (0.1, 0.3, 0.5, 0.8, 0.9) and the error term ε ∼ χ 2 (3) in the location-scale-shift scenario.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Econometric Analysis of Panel Data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Baltagi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Baltagi, B. (2008). Econometric Analysis of Panel Data. John Wiley &amp; Sons.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On efficient estimation with panel data: An empirical comparison of instrumental variables estimators</title>
		<author>
			<persName><forename type="first">B</forename><surname>Baltagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khanti-Akom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Econometrics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="406"/>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Baltagi, B. and Khanti-Akom, S. (1990). On efficient estimation with panel data: An empirical comparison of instrumental variables estimators. Journal of Applied Econometrics, 5(4):401-06.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nonparametric and Semiparametric Methods in Econometrics and Statistics</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Tauchen</surname></persName>
		</author>
		<idno>wHTszJdi2H0C</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Symposium in Economic Theory and Econometrics</title>
		<meeting>the Fifth International Symposium in Economic Theory and Econometrics</meeting>
		<imprint>
			<publisher>Google-Books</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barnett, W. A., Powell, J., and Tauchen, G. E. (1991). Nonparametric and Semiparametric Methods in Econometrics and Statistics: Proceedings of the Fifth International Symposium in Economic Theory and Econometrics. Cambridge University Press. Google-Books-ID: wHTszJdi2H0C.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Oualkacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Charpentier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.09214</idno>
		<idno>arXiv: 1810.09214</idno>
		<title level="m">A new GEE method to account for heteroscedasticity, using asymmetric least-square regressions</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barry, A., Oualkacha, K., and Charpentier, A. (2020). A new GEE method to account for het- eroscedasticity, using asymmetric least-square regressions. arXiv:1810.09214 [stat]. arXiv: 1810.09214.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalized bootstrap for estimators of minimizers of convex functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="239"/>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bose, A. and Chatterjee, S. (2003). Generalized bootstrap for estimators of minimizers of convex functions. Journal of Statistical Planning and Inference, 117(2):225-239.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fixed-Effects Panel Regression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brüderl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ludwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The SAGE Handbook of Regression Analysis and Causal Inference</title>
		<imprint>
			<publisher>SAGE Publications Ltd</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="327" to="358"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Brüderl, J. and Ludwig, V. (2014). Fixed-Effects Panel Regression. In The SAGE Handbook of Regression Analysis and Causal Inference, pages 327-358. SAGE Publications Ltd.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Trivedi</surname></persName>
		</author>
		<title level="m">Microeconometrics</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cameron, A. and Trivedi, P. (2005). Microeconometrics. Cambridge University Press.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A simple approach to quantile regression for panel data</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Canay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Econometrics Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="368" to="386"/>
			<date type="published" when="2011">2011</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Canay, I. A. (2011). A simple approach to quantile regression for panel data. The Econometrics Journal, 14(3):368-386. Publisher: Wiley.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Estimating the Return to Schooling: Progress on Some Persistent Econometric Problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Card, D. (2001). Estimating the Return to Schooling: Progress on Some Persistent Econometric Problems. Econometrica, 69(5).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Quantile Regression for Correlated Observations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Parzen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="51" to="69"/>
			<pubPlace>New York, New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen, L., Wei, L.-J., and Parzen, M. I. (2004). Quantile Regression for Correlated Observations, pages 51-69. Springer New York, New York, NY.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient estimation with panel data: An empirical comparison of instrumental variables estimators</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cornwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rupert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Econometrics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="155"/>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cornwell, C. and Rupert, P. (1988). Efficient estimation with panel data: An empirical comparison of instrumental variables estimators. Journal of Applied Econometrics, 3(2):149-55.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Penalized quantile regression for dynamic panel data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Galvao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Montes-Rojas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3476" to="3497"/>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>cited By (since 1996</note>
	<note type="raw_reference">Galvao, A. and Montes-Rojas, G. (2010). Penalized quantile regression for dynamic panel data. Journal of Statistical Planning and Inference, 140(11):3476-3497. cited By (since 1996)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Functional estimation of extreme conditional expectiles</title>
		<author>
			<persName><forename type="first">S</forename><surname>Girard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stupfler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Usseglio-Carleve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrics and Statistics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Girard, S., Stupfler, G., and Usseglio-Carleve, A. (2021). Functional estimation of extreme condi- tional expectiles. Econometrics and Statistics.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Econometric analysis</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Greene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Upper Saddle River, N.J.</pubPlace>
		</imprint>
	</monogr>
	<note>7th ed.. edition</note>
	<note type="raw_reference">Greene, W. H. (2011). Econometric analysis. Prentice Hall, Upper Saddle River, N.J., 7th ed.. edition.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Practical Confidence Intervals for Regression Quantiles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kocherginsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="55"/>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kocherginsky, M., He, X., and Mu, Y. (2005). Practical Confidence Intervals for Regression Quan- tiles. Journal of Computational and Graphical Statistics, 14(1):41-55.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Quantile regression for longitudinal data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Koenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="89"/>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Koenker, R. (2004). Quantile regression for longitudinal data. Journal of Multivariate Analysis, 91(1):74-89.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">quantreg: Quantile Regression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Koenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">R package version</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Koenker, R. (2018). quantreg: Quantile Regression. R package version 5.36</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">rqpd: Regression Quantiles for Panel Data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Koenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Bache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">R package version</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="6" to="10"/>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Koenker, R. and Bache, S. H. (2014). rqpd: Regression Quantiles for Panel Data. R package version 0.6/r10.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust penalized quantile regression estimation for panel data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lamarche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="396" to="408"/>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lamarche, C. (2010). Robust penalized quantile regression estimation for panel data. Journal of Econometrics, 157(2):396-408.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Simultaneous multiple non-crossing quantile regression estimation using kernel constraints</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Nonparametric Statistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="415" to="437"/>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu, Y. and Wu, Y. (2011). Simultaneous multiple non-crossing quantile regression estimation using kernel constraints. Journal of Nonparametric Statistics, 23(2):415-437.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">microbenchmark: Accurate Timing Functions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Mersmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">R package version</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4" to="7"/>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mersmann, O. (2019). microbenchmark: Accurate Timing Functions. R package version 1.4-7.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Asymmetric least squares estimation and testing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Newey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="819" to="847"/>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Newey, W. K. and Powell, J. L. (1987). Asymmetric least squares estimation and testing. Econo- metrica, 55(4):819-47.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R Core Team (2021). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">expectreg: Expectile and Quantile Regression</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sobotka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Waltrup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Eilers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kneib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kauermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">R package version</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sobotka, F., Schnabel, S., Waltrup, L. S., Eilers, P., Kneib, T., and Kauermann, G. (2014). expectreg: Expectile and Quantile Regression. R package version 0.39</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Maternal and fetal genetic effects on birth weight and their relevance to cardio-metabolic risk factors</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Warrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Beaumont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Genetics</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="804" to="814"/>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Warrington, N. M., Beaumont, R. N., and al. (2019). Maternal and fetal genetic effects on birth weight and their relevance to cardio-metabolic risk factors. Nature Genetics, 51(5):804-814.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity</title>
		<author>
			<persName><forename type="first">H</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="817" to="838"/>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
	<note type="raw_reference">White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. Econometrica, 48(4):817-38.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Quantile Regression Models with Multivariate Failure Time Data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0006-341X.2005.030815.x</idno>
		<ptr target="https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.0006-341X.2005.030815.x"/>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="161"/>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yin, G. and Cai, J. (2005). Quantile Regression Models with Multivariate Failure Time Data. Biometrics, 61(1):151-161. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.0006- 341X.2005.030815.x.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>